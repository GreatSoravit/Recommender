{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Ys992pU79yhD"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from typing import List, Tuple, Sequence\n",
    "SEED=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hg093kVRAvHw",
    "outputId": "0726ba2c-e78d-421d-9c78-684efb87e542"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0  955k    0  1183    0     0   3853      0  0:04:13 --:--:--  0:04:13  3840\n",
      " 44  955k   44  428k    0     0   327k      0  0:00:02  0:00:01  0:00:01  327k\n",
      "100  955k  100  955k    0     0   551k      0  0:00:01  0:00:01 --:--:--  551k\n",
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!curl -o ml-latest-small.zip http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
    "# backup location\n",
    "#!curl -o ml-latest-small.zip http://www.dcs.gla.ac.uk/~craigm/recsysHM/ml-latest-small.zip\n",
    "!unzip -o ml-latest-small.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Yss68U_EA0w2"
   },
   "outputs": [],
   "source": [
    "ratings_df = pd.read_csv(\"ml-latest-small/ratings.csv\")\n",
    "movies_df = pd.read_csv(\"ml-latest-small/movies.csv\")\n",
    "\n",
    "# treat userId as strings, and similarly as movies. This will prevent confusion later on.\n",
    "ratings_df['userId'] =  \"u\" + ratings_df['userId'].astype(str)\n",
    "ratings_df['movieId'] = \"m\" + ratings_df['movieId'].astype(str)\n",
    "movies_df['movieId'] = \"m\" +  movies_df['movieId'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "id": "o5QQBZ3QS2Hv",
    "outputId": "21f0da7c-1a92-4ea6-bd7c-12b3576817b7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u1</td>\n",
       "      <td>m1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u1</td>\n",
       "      <td>m3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u1</td>\n",
       "      <td>m6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u1</td>\n",
       "      <td>m47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u1</td>\n",
       "      <td>m50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  userId movieId  rating  timestamp\n",
       "0     u1      m1     4.0  964982703\n",
       "1     u1      m3     4.0  964981247\n",
       "2     u1      m6     4.0  964982224\n",
       "3     u1     m47     5.0  964983815\n",
       "4     u1     m50     5.0  964982931"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u1</td>\n",
       "      <td>m1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u1</td>\n",
       "      <td>m3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u1</td>\n",
       "      <td>m6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u1</td>\n",
       "      <td>m47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u1</td>\n",
       "      <td>m50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>u1</td>\n",
       "      <td>m3744</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964980694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>u1</td>\n",
       "      <td>m3793</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964981855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>u1</td>\n",
       "      <td>m3809</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>u1</td>\n",
       "      <td>m4006</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>u1</td>\n",
       "      <td>m5060</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964984002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>232 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    userId movieId  rating  timestamp\n",
       "0       u1      m1     4.0  964982703\n",
       "1       u1      m3     4.0  964981247\n",
       "2       u1      m6     4.0  964982224\n",
       "3       u1     m47     5.0  964983815\n",
       "4       u1     m50     5.0  964982931\n",
       "..     ...     ...     ...        ...\n",
       "227     u1   m3744     4.0  964980694\n",
       "228     u1   m3793     5.0  964981855\n",
       "229     u1   m3809     4.0  964981220\n",
       "230     u1   m4006     4.0  964982903\n",
       "231     u1   m5060     5.0  964984002\n",
       "\n",
       "[232 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df[ratings_df['userId']=='u1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9742"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movies_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "id": "eMfsveWjS4xP",
    "outputId": "31ae973b-f1d2-47d2-bb5e-0ac2e1fd373d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>m2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>m4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>m5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  movieId                               title  \\\n",
       "0      m1                    Toy Story (1995)   \n",
       "1      m2                      Jumanji (1995)   \n",
       "2      m3             Grumpier Old Men (1995)   \n",
       "3      m4            Waiting to Exhale (1995)   \n",
       "4      m5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                   Adventure|Children|Fantasy  \n",
       "2                               Comedy|Romance  \n",
       "3                         Comedy|Drama|Romance  \n",
       "4                                       Comedy  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-rAIXwDoBCda"
   },
   "source": [
    "# User-based CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "LKsmW549BNlq",
    "outputId": "4ee0cdf9-2f1a-4627-946e-ccfb894f21da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movieId</th>\n",
       "      <th>m1</th>\n",
       "      <th>m10</th>\n",
       "      <th>m100</th>\n",
       "      <th>m100044</th>\n",
       "      <th>m100068</th>\n",
       "      <th>m100083</th>\n",
       "      <th>m100106</th>\n",
       "      <th>m100159</th>\n",
       "      <th>m100163</th>\n",
       "      <th>m100194</th>\n",
       "      <th>...</th>\n",
       "      <th>m99750</th>\n",
       "      <th>m99764</th>\n",
       "      <th>m998</th>\n",
       "      <th>m99813</th>\n",
       "      <th>m99846</th>\n",
       "      <th>m99853</th>\n",
       "      <th>m999</th>\n",
       "      <th>m99910</th>\n",
       "      <th>m99917</th>\n",
       "      <th>m99992</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>u1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u100</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u101</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u102</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u95</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u96</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u97</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u98</th>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u99</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>610 rows Ã— 9724 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "movieId   m1  m10  m100  m100044  m100068  m100083  m100106  m100159  m100163  \\\n",
       "userId                                                                          \n",
       "u1       4.0  0.0   0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "u10      0.0  0.0   0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "u100     0.0  0.0   0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "u101     0.0  0.0   0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "u102     0.0  0.0   0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "...      ...  ...   ...      ...      ...      ...      ...      ...      ...   \n",
       "u95      0.0  0.0   0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "u96      5.0  0.0   0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "u97      0.0  0.0   0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "u98      4.5  0.0   0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "u99      0.0  4.0   0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "movieId  m100194  ...  m99750  m99764  m998  m99813  m99846  m99853  m999  \\\n",
       "userId            ...                                                       \n",
       "u1           0.0  ...     0.0     0.0   0.0     0.0     0.0     0.0   0.0   \n",
       "u10          0.0  ...     0.0     0.0   0.0     0.0     0.0     0.0   0.0   \n",
       "u100         0.0  ...     0.0     0.0   0.0     0.0     0.0     0.0   0.0   \n",
       "u101         0.0  ...     0.0     0.0   0.0     0.0     0.0     0.0   0.0   \n",
       "u102         0.0  ...     0.0     0.0   0.0     0.0     0.0     0.0   0.0   \n",
       "...          ...  ...     ...     ...   ...     ...     ...     ...   ...   \n",
       "u95          0.0  ...     0.0     0.0   0.0     0.0     0.0     0.0   0.0   \n",
       "u96          0.0  ...     0.0     0.0   0.0     0.0     0.0     0.0   0.0   \n",
       "u97          0.0  ...     0.0     0.0   0.0     0.0     0.0     0.0   0.0   \n",
       "u98          0.0  ...     0.0     0.0   0.0     0.0     0.0     0.0   0.0   \n",
       "u99          0.0  ...     0.0     0.0   0.0     0.0     0.0     0.0   0.0   \n",
       "\n",
       "movieId  m99910  m99917  m99992  \n",
       "userId                           \n",
       "u1          0.0     0.0     0.0  \n",
       "u10         0.0     0.0     0.0  \n",
       "u100        0.0     0.0     0.0  \n",
       "u101        0.0     0.0     0.0  \n",
       "u102        0.0     0.0     0.0  \n",
       "...         ...     ...     ...  \n",
       "u95         0.0     0.0     0.0  \n",
       "u96         0.0     0.0     0.0  \n",
       "u97         0.0     0.0     0.0  \n",
       "u98         0.0     0.0     0.0  \n",
       "u99         0.0     0.0     0.0  \n",
       "\n",
       "[610 rows x 9724 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_df_matrix = ratings_df.pivot_table(index='userId', columns='movieId', values='rating').fillna(0)\n",
    "r_df_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movieId\n",
       "m1         4.0\n",
       "m10        0.0\n",
       "m100       0.0\n",
       "m100044    0.0\n",
       "m100068    0.0\n",
       "          ... \n",
       "m99853     0.0\n",
       "m999       0.0\n",
       "m99910     0.0\n",
       "m99917     0.0\n",
       "m99992     0.0\n",
       "Name: u1, Length: 9724, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_df_matrix.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RRIXYwQgBRt2",
    "outputId": "40ef1655-3901-413e-a7e5-49aa071c2136"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['u1', 'u10', 'u100', 'u101', 'u102', 'u103', 'u104', 'u105', 'u106',\n",
       "       'u107',\n",
       "       ...\n",
       "       'u90', 'u91', 'u92', 'u93', 'u94', 'u95', 'u96', 'u97', 'u98', 'u99'],\n",
       "      dtype='object', name='userId', length=610)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_df_matrix.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "77XOSOdqBXmw",
    "outputId": "9f80640d-b53d-426c-8c0e-bd642689ef9f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movieId\n",
       "m1         4.0\n",
       "m10        0.0\n",
       "m100       0.0\n",
       "m100044    0.0\n",
       "m100068    0.0\n",
       "          ... \n",
       "m99853     0.0\n",
       "m999       0.0\n",
       "m99910     0.0\n",
       "m99917     0.0\n",
       "m99992     0.0\n",
       "Name: u1, Length: 9724, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_df_matrix.loc['u1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9NXXbCQsBbJW",
    "outputId": "9650a462-eb66-4668-b0f0-19c22dd6d976"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between userId=1 and itself is:\n",
      "1.0\n",
      "Cosine similarity between userId=1 and userId=607 is:\n",
      "0.2693892401115333\n"
     ]
    }
   ],
   "source": [
    "# User-based CF heavily relies upon Cosine similarity.\n",
    "def cos_sim(a, b):\n",
    "  from numpy.linalg import norm\n",
    "  from numpy import dot\n",
    "  return dot(a, b)/(norm(a)*norm(b))\n",
    "\n",
    "print('Cosine similarity between userId=1 and itself is:')\n",
    "print(cos_sim(r_df_matrix.loc['u1'].values, r_df_matrix.loc['u1'].values))\n",
    "\n",
    "print('Cosine similarity between userId=1 and userId=607 is:')\n",
    "print(cos_sim(r_df_matrix.loc['u1'].values, r_df_matrix.loc['u607'].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B061AiTiBlWJ"
   },
   "source": [
    "## 1. Get the most similar users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rj1wpnS7BbMF",
    "outputId": "a7a2ce22-01da-4bc4-dfa0-8cf6a1b00f77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['u313'], [0.07818732282993371])\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import rankdata\n",
    "#identify the userIds of the k most similar users to the specified\n",
    "#userId, and their corresponding cosine similarities.\n",
    "def get_most_similar_users(userId : str, k : int = 10) -> Tuple[Sequence[str], Sequence[float]]:\n",
    "\n",
    "  # Get index of all user \n",
    "  all_user = r_df_matrix.index\n",
    "  list_usr,list_cos = list(),list()\n",
    "  # Compute cosine similarity between input user and other users except itself then save in list\n",
    "  for usr in all_user:\n",
    "    # Exclude user itself\n",
    "    if usr != userId:\n",
    "      list_usr.append(usr)\n",
    "      list_cos.append(cos_sim(r_df_matrix.loc[userId].values, r_df_matrix.loc[usr].values))\n",
    "\n",
    "  # Change list to array and get only index that not include zero\n",
    "  array_usr = np.asarray(list_usr)\n",
    "  array_cos = np.asarray(list_cos)\n",
    "  usr_no_zero = array_usr[np.nonzero(array_cos)]\n",
    "  cos_no_zero = array_cos[np.nonzero(array_cos)]\n",
    "\n",
    "  # Ranking by multiply -1 to cosine value before using rankdata to get higher number be the first rank\n",
    "  ranking = rankdata([-1 * i for i in cos_no_zero])\n",
    "\n",
    "  topk_userids = [] # a list/numpy array of k userIds of top-k users\n",
    "  topk_cosines = []  # a list/numpy array of k cosine similarity values\n",
    "\n",
    "  # Find userid and it cosine value in k rank then save in list\n",
    "  for i in range(1,k+1):\n",
    "    topk_userids.append(usr_no_zero[np.where(ranking == i)][0]) \n",
    "    topk_cosines.append(cos_no_zero[np.where(ranking == i)][0])\n",
    "\n",
    "  return (topk_userids, topk_cosines)\n",
    "\n",
    "print(get_most_similar_users(userId='u3', k=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z3jnW2BCAIWR"
   },
   "source": [
    "You can now answer the questions corresponding to Task 1 in the quiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UVnsPTKjzqnD",
    "outputId": "19b8b416-a3f3-418c-b051-925a449caa77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['u159'], [0.28826463078187997])\n"
     ]
    }
   ],
   "source": [
    "print(get_most_similar_users(userId='u10', k=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PIMwvzqJ2YuE",
    "outputId": "ce52b726-c3bd-45a6-dc4b-3ce945cedad9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['u453', 'u45'], [0.27983214052930266, 0.26236874974336444])\n"
     ]
    }
   ],
   "source": [
    "print(get_most_similar_users(userId='u500', k=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t9ZepSCnBwc7"
   },
   "source": [
    "## 2. Predict ratings via user-based CF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0eX33RkTBbS2",
    "outputId": "3b5523f0-2abe-4cb8-f172-209caec2bcf0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted rating: 2.3363751766665386\n",
      "Actual rating: 4.0\n"
     ]
    }
   ],
   "source": [
    "def predict_rating(userId : str, movieId : str) -> float:\n",
    "\n",
    "  # Get list of most similar user for 10 nearest neighbours\n",
    "  sim_usr = get_most_similar_users(userId=userId, k=10)\n",
    "  sim_rating = 0\n",
    "\n",
    "  # Get movie rating value from list of most similar user and compute overall rating\n",
    "  for i in range(0,len(sim_usr[0])):\n",
    "    rating_val = r_df_matrix.loc[sim_usr[0][i]][movieId]\n",
    "    sim_rating += sim_usr[1][i] * rating_val\n",
    "\n",
    "  predicted = sim_rating / np.sum(sim_usr[1])  # predicted rating value\n",
    "  return predicted\n",
    "\n",
    "print(\"Predicted rating:\", predict_rating(userId='u1', movieId='m1'))\n",
    "\n",
    "print(\"Actual rating:\", r_df_matrix.loc['u1']['m1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CqfUghVsCA7G"
   },
   "source": [
    "## 3. Predict ratings via user-based CF with Mean-center normalisation.\n",
    "\n",
    "Users usually rate differently: (1) some rate high, while others low. (2) Some use more of the scale than others. However, the user-based CF implemented above ignores these differences. To this end, apply normalisation to compensate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-Q5Efb4zB5_O",
    "outputId": "0b2d0f6a-4f27-4710-98ae-eec8b24e76bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean rating of user u5: 3.6363636363636362\n",
      "Predicted rating: 3.127985053034213\n",
      "Actual rating: 4.0\n"
     ]
    }
   ],
   "source": [
    "def mean_rating(userId : str) -> float:\n",
    "\n",
    "  # Compute average rating by get all user ratings that is not zero then find mean\n",
    "  mean_rating = np.mean(r_df_matrix.loc[userId][r_df_matrix.loc[userId] > 0]) # mean-centering value\n",
    "  return mean_rating\n",
    "\n",
    "print(\"Mean rating of user u5:\", mean_rating('u5') )\n",
    "\n",
    "def predict_rating_MC(userId : str, movieId : str) -> float:\n",
    "\n",
    "  # Get list of most similar user for 10 nearest neighbours and average rating of input user\n",
    "  sim_usr = get_most_similar_users(userId=userId, k=10)\n",
    "\n",
    "  user_mean_rating = mean_rating(userId)\n",
    "  sim_rating = 0\n",
    "\n",
    "  # Get movie rating value from list of most similar user and find their average rating then compute overall rating\n",
    "  for i in range(0,len(sim_usr[0])):\n",
    "    rating_val = r_df_matrix.loc[sim_usr[0][i]][movieId]\n",
    "    avg_rating = mean_rating(sim_usr[0][i])\n",
    "    sim_rating += sim_usr[1][i] * ( rating_val - avg_rating )\n",
    "  predicted = user_mean_rating + ( sim_rating / np.sum(sim_usr[1]) ) # predicted rating value with mean-centering\n",
    "  return predicted\n",
    "\n",
    "print(\"Predicted rating:\", predict_rating_MC('u1', 'm1'))\n",
    "print(\"Actual rating:\", r_df_matrix.loc['u1']['m1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZN_OpdQYHmTb"
   },
   "source": [
    "### Explicit Matrix Factorisation using Spotlight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L0oobMGk5eqv"
   },
   "source": [
    "the Spotlight library -  https://github.com/maciejkula/spotlight - and  documentation at https://maciejkula.github.io/spotlight/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cDObURPI-Shz",
    "outputId": "704e067c-85e7-48ef-c263-3ec02b10c86d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spotlight from git+https://github.com/cmacdonald/spotlight.git@master#egg=spotlight in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (0.1.6)\n",
      "Requirement already satisfied: torch>=0.4.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from spotlight) (1.8.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from torch>=0.4.0->spotlight) (1.19.5)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from torch>=0.4.0->spotlight) (3.7.4.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/cmacdonald/spotlight.git@master#egg=spotlight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nqoiteq7IJzJ"
   },
   "source": [
    "Now we can get onto some real recommendation work. Spotlight has a handy [Interactions](https://maciejkula.github.io/spotlight/interactions.html) object, which encapsulates the basics of a recommendation dataset.\n",
    "\n",
    "In fact, there are handy loaders for a few standard datasets including MovieLens, but let's make our own, so that we can match back to the dataframe.\n",
    "\n",
    "Interactions need numbers as userids and itemids. Unfortunately, our MovieLens uses numbers, but these aren't consecutive (i.e. we have missing movieIds values). They are also strings (i.e. movieIds start with \"m\" and userIds start with \"u\").\n",
    "\n",
    "Hence, for both movies and users, we will use [defaultdict](https://docs.python.org/3/library/collections.html#collections.defaultdict) to convert the MovieLens strings down to consecutive integers for use in Spotlight, in the `uid_map` and `iid_map` objects. We'll keep the reverse mapping around too, in case we want to lookup the actual movieId given the uid recorded by SpotlightÂ (etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oF89PzxNHrHq",
    "outputId": "860e4ad8-ff5c-4fb1-b570-d630d4a6b1fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "610 users 9724 item\n",
      "userId u556 got uid 555\n",
      "movieId m54001 got iid 2518\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from itertools import count\n",
    "\n",
    "#create userId -> uid mapping dictionary. the next assigned value is the current size.\n",
    "uid_map = defaultdict(count().__next__)\n",
    "#ditto for movieId -> iid\n",
    "iid_map = defaultdict(count().__next__)\n",
    "\n",
    "#uids is an array of integers corresponding to the userId for every row in ratings_df\n",
    "#uid_map does the assignment of new uid values, or reusing the uid value assigned for\n",
    "#each userId\n",
    "uids = np.array([uid_map[uid] for uid in ratings_df[\"userId\"].values ], dtype=np.int32)\n",
    "#similar for iids\n",
    "iids = np.array([iid_map[iid] for iid in ratings_df[\"movieId\"].values ], dtype=np.int32)\n",
    "\n",
    "#freeze uid_map and iid_map so no more mappings are created\n",
    "uid_map.default_factory = None\n",
    "iid_map.default_factory = None\n",
    "\n",
    "#reverse them, so we can go from iid (int) to itemId (str)\n",
    "uid_rev_map = {v: k for k, v in uid_map.items()}\n",
    "iid_rev_map = {v: k for k, v in iid_map.items()}\n",
    "num_items = len(iid_map)\n",
    "num_users = len(uid_map)\n",
    "\n",
    "print(\"%d users %d item\" % (num_users, num_items))\n",
    "\n",
    "ratings = ratings_df[\"rating\"].values.astype(np.float32)\n",
    "timestamps = ratings_df[\"timestamp\"].values.astype(np.int32)\n",
    "\n",
    "print(\"userId %s got uid %d\" % (\"u556\", uid_map[\"u556\"]))\n",
    "print(\"movieId %s got iid %d\" % (\"m54001\", iid_map[\"m54001\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hDwZYy2xY3-D"
   },
   "source": [
    "## On towards MF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gMejAIwPNVrU"
   },
   "source": [
    "Now let's build a Spotlight [Interactions](https://maciejkula.github.io/spotlight/interactions.html) object. This contains everything that Spotlight needs to train a model. We can split it up randomly into train and test subsets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "cg2tNWwPIBfu"
   },
   "outputs": [],
   "source": [
    "from spotlight.interactions import Interactions\n",
    "from spotlight.cross_validation import random_train_test_split\n",
    "\n",
    "dataset = Interactions(user_ids=uids,\n",
    "                                  item_ids=iids,\n",
    "                                  ratings=ratings,\n",
    "                                  timestamps=timestamps)\n",
    "\n",
    "#lets initialise the seed, so that its repeatable and reproducible \n",
    "train, test = random_train_test_split(dataset, random_state=np.random.RandomState(SEED))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1shoeRmWKXxS"
   },
   "source": [
    "Let's see how big the two datasets are. What is the train/test split percentage size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "cellView": "code",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XcjOWJ-qIEge",
    "outputId": "65db2802-fd82-4da9-87e0-84cf17e80d37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Interactions dataset (610 users x 9724 items x 80668 interactions)>\n",
      "<Interactions dataset (610 users x 9724 items x 20168 interactions)>\n"
     ]
    }
   ],
   "source": [
    "print(train)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aTyhLswNulTX"
   },
   "source": [
    "Now, you can think of the Interaction objects are being the partitions of the rating matrix. But we don't store it as a single big matrix. Instead, we record three one-dimensional arrays:\n",
    " \n",
    "  * one for the ids of the users\n",
    "  * one for the ids of the items\n",
    "  * one for the actual rating values.\n",
    "\n",
    "Each of these arrays is the size of the number of ratings (80668 for the training set).\n",
    "\n",
    "In essence, Interactions is a sparse matrix - for each rating, we record its x and y position, as well as the rating itself.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "74iQtBOoUZJ1",
    "outputId": "b0b7563e-805a-41c2-9f38-3a42fbeafb47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80668,)\n",
      "(80668,)\n",
      "(80668,)\n"
     ]
    }
   ],
   "source": [
    "print(train.item_ids.shape)\n",
    "print(train.user_ids.shape)\n",
    "print(train.ratings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2V9Hx3dhUjI1"
   },
   "source": [
    "For instance, let's look at the first rating:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sz46dNMkUrCC",
    "outputId": "05065eaf-4e45-4414-f901-f41637794066"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uid 56 gave iid 1491 a rating of 2\n"
     ]
    }
   ],
   "source": [
    "print(\"uid %d gave iid %d a rating of %d\" % (train.user_ids[0], train.item_ids[0],train.ratings[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "47QmgWtYvM4u",
    "outputId": "b7de4877-dce3-45b5-ae5e-54a0f3f82aaa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6082 6087  457 1925 7951 1132  764 5989  753 1342 1893 3076 3258 1182\n",
      " 1938 1894 4796  926  770 8659 2059  917 1077  912  779  322 1307 3087\n",
      " 2518  774]\n",
      "[4.  3.5 5.  5.  4.  4.  4.  4.  4.5 4.  4.  4.5 4.  4.  4.5 3.5 4.  4.\n",
      " 4.  4.  4.  3.5 5.  2.5 4.  5.  4.  4.  4.  4. ]\n"
     ]
    }
   ],
   "source": [
    "# map userId to the internal uid value\n",
    "userId = \"u556\"\n",
    "uid = uid_map.get(userId)\n",
    "\n",
    "# see which ratings are for this user. Use this to filter the item and ratings arrays. \n",
    "# here we are filtering a numpy array based on an array of True/False values. Its just\n",
    "# like filtering a Pandas data frame.\n",
    "print(train.item_ids[train.user_ids == uid])\n",
    "print(train.ratings[train.user_ids == uid])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RhnKAa-KKclT"
   },
   "source": [
    "We can now learn a model. Let's start with a matrix factorisation for explicit data.  We train the model using the `fit` method. This is just like the `fit` in Sklearn - we're fitting  a model to the specified training data.\n",
    "\n",
    "This might take upto a minute. \n",
    "\n",
    "**NB:**  Spotlight can support using GPUs which we could use to slightly speed up training time, but that will make our life more difficult later on, so let's ignore this for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UduCmnlbKt-O",
    "outputId": "66b6fbcc-2484-45af-a001-0a8318ecee85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss 4.308109072190296\n",
      "Epoch 1: loss 0.8099100989631459\n",
      "Epoch 2: loss 0.5096786611630947\n",
      "Epoch 3: loss 0.36366338669499265\n",
      "Epoch 4: loss 0.2919712712681746\n",
      "Epoch 5: loss 0.256977399221704\n",
      "Epoch 6: loss 0.2364347950567173\n",
      "Epoch 7: loss 0.22271785323944274\n",
      "Epoch 8: loss 0.21399798956287058\n",
      "Epoch 9: loss 0.20728879473820516\n",
      "Training took 18 seconds \n"
     ]
    }
   ],
   "source": [
    "from spotlight.factorization.explicit import ExplicitFactorizationModel\n",
    "import time  \n",
    "\n",
    "emodel = ExplicitFactorizationModel(n_iter=10,\n",
    "                                    embedding_dim=32, #this is Spotlight default\n",
    "                                    use_cuda=False,\n",
    "                                    random_state=np.random.RandomState(SEED) # ensure results are repeatable\n",
    ")\n",
    "current = time.time()\n",
    "\n",
    "emodel.fit(train, verbose=True)\n",
    "\n",
    "end = time.time()\n",
    "diff = end - current\n",
    "print(\"Training took %d seconds \"% (diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cTTK1BlbLL_t"
   },
   "source": [
    "How well did we do. Well, let's give a look at the recommentations, for our specific user, userId u556. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zjyVPjoGLoy6",
    "outputId": "ade433b6-3f91-4b4c-90f9-1de48b9b22bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One test item_id for userId u556 (uid 555) is \n",
      "Test movieId is m74530 iid 8141 \n",
      "Predicted rating for 'Percy Jackson & the Olympians: The Lightning Thief (2010)' was 2.574092, actual rating 3.5, error was 0.925908\n"
     ]
    }
   ],
   "source": [
    "userId = \"u556\"\n",
    "\n",
    "# convert the string to the internal integer\n",
    "uid = uid_map.get(userId)\n",
    "print(\"One test item_id for userId %s (uid %d) is \" % (userId, uid))\n",
    "\n",
    "# pick one rating that the user made\n",
    "testItemId = test.item_ids[test.user_ids == uid][0] \n",
    "print(\"Test movieId is %s iid %d \" % (iid_rev_map.get(testItemId), testItemId ) )\n",
    "\n",
    "\n",
    "#here 0 is a dummy item, which Spotlight needs for some reason...\n",
    "#we discard its prediction using [1]\n",
    "predicted = emodel.predict( np.array([uid]), item_ids=np.array([0, testItemId]) )[1]\n",
    "\n",
    "#what was the actual score of the user for that movie?\n",
    "#we can get the appropriate row from the ratings dataframe, then extract that value\n",
    "actual = ratings_df[(ratings_df.movieId==iid_rev_map.get(testItemId)) & (ratings_df.userId==userId)][\"rating\"].values[0]\n",
    "\n",
    "\n",
    "def getMovieTitle(iid):\n",
    "  return movies_df[movies_df['movieId'] == iid_rev_map.get(iid)][\"title\"].values[0]\n",
    "\n",
    "print(\"Predicted rating for '%s' was %f, actual rating %0.1f, error was %f\" % (getMovieTitle(testItemId), predicted, actual, abs(predicted-actual) )) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zWdWW8QhacOw"
   },
   "source": [
    "So this is interesting - while we saw above that the users liked fantasy movies, we predicted a rating of $\\sim 2.5$, but the user gave this particular movie a 3.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BgX01Wwlr_WA"
   },
   "source": [
    "We can also ask for **all** of the recommendations for a given user:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fz28wrmIsDa-",
    "outputId": "f7c029e3-dd26-478c-ea24-d06faddbe631"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.9689283  4.3499813  4.5101576  ... 0.87423575 2.7873082  0.9850699 ]\n",
      "9724\n",
      "2.5740924\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "allpreds = emodel.predict( np.array([uid]) )\n",
    "\n",
    "print(allpreds)\n",
    "print(allpreds.size)\n",
    "\n",
    "#we can recover the original rating for our test item \n",
    "print(allpreds[testItemId])\n",
    "\n",
    "# lets just check we got the correct prediction\n",
    "print(allpreds[testItemId] - actual < 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d25P7AtBPgXS"
   },
   "source": [
    "## Latent Factors (aka Embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "cellView": "both",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jf2Em9KSa74G",
    "outputId": "43d66870-0f16-427c-dadf-3a8e33cc5531"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1223, -0.3951, -0.3488,  0.0474,  0.7867, -0.0242,  0.2448,  0.7672,\n",
       "        -0.1924, -0.0686, -0.1228,  0.6061, -0.1798, -0.3621,  0.7326,  0.2025,\n",
       "        -0.1660, -0.3077, -0.3590, -0.3852,  0.2369, -0.6257,  0.7370,  0.8468,\n",
       "         0.0755, -0.4360, -0.1154, -0.2451, -0.0357, -0.0060,  0.1001,  0.2164],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the embedding of an item is a PyTorch tensor of size 32\n",
    "#a PyTorch tensor can be thought of having similar semantics as an numpy array.\n",
    "print(emodel._net.item_embeddings.weight[0].shape)\n",
    "emodel._net.item_embeddings.weight[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VcKlJIBoVNYr"
   },
   "source": [
    "We can check how Spotlight makes its prediction. The key line is https://github.com/maciejkula/spotlight/blob/master/spotlight/factorization/representations.py#L89\n",
    "\n",
    "This takes the (dot-)product of the user's \"embedding\" (latent factor) and the item's embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g14v62m4YRyd",
    "outputId": "4abef9a6-721b-4b7d-f8bc-5a2dfc0bb25e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percy Jackson & the Olympians: The Lightning Thief (2010)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[2.5741]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# uid=555 for u556\n",
    "# testItemId is our item of interest\n",
    "\n",
    "dotprod = (emodel._net.user_embeddings.weight[uid] * emodel._net.item_embeddings.weight[testItemId]).sum(0)\n",
    "user_bias = emodel._net.user_biases(torch.tensor([uid]))\n",
    "item_bias = emodel._net.item_biases(torch.tensor([testItemId], dtype=torch.long))\n",
    "\n",
    "print(getMovieTitle(testItemId))\n",
    "\n",
    "dotprod + user_bias + item_bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VE2tpcJb8e7"
   },
   "source": [
    "## 4. Examining Latent Factors\n",
    "\n",
    "Let's give a look at item-item similarities. Write a function `mostsimilar(targetMovieId, model)` that identifies the most similar movieId to the specified target, based on the Cosine similarity of their item embedding vectors. \n",
    "\n",
    "What's the closest movie to \"Harry Potter and the Deathly Hallows: Part 1 (2010)\" , which is movieId m81834 in the MovieLens dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O7fDGUx6fBR3",
    "outputId": "2c47f0a0-4861-43ec-ee57-8683dd8fbab4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "nn.functional.cosine_similarity(\n",
    "     torch.tensor([1.0,0]),\n",
    "     torch.tensor([0,1.0],), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0Rg_DuBnoMEu",
    "outputId": "11481d42-cb3c-4a5d-df57-6f6f723ea5f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9724\n",
      "targetMovieId = m81834 'Harry Potter and the Deathly Hallows: Part 1 (2010)' (iid 1933)\n",
      "mostSimilar = m69844 (iid 917) with cosine of 0.793590 \n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "def mostsimilar(targetIId : int, model):\n",
    "  highest=0\n",
    "  highestCos=0\n",
    "\n",
    "  # Use cosine similarity between input movie and other movies then find highest cosine similarity\n",
    "  for mvid in iid_map:\n",
    "    if targetIId != iid_map[mvid]:\n",
    "      sim_val = nn.functional.cosine_similarity(\n",
    "      model._net.item_embeddings.weight[targetIId],\n",
    "      model._net.item_embeddings.weight[iid_map[mvid]], dim=0)\n",
    "\n",
    "      if sim_val > highestCos:\n",
    "        highest = iid_map[mvid]\n",
    "        highestCos = sim_val\n",
    "\n",
    "  #####################\n",
    "\n",
    "  print(train.num_items)\n",
    "  print(\"targetMovieId = %s '%s' (iid %d)\" % (iid_rev_map.get(targetIId), getMovieTitle(targetIId), targetIId))\n",
    "  print(\"mostSimilar = %s (iid %d) with cosine of %f \" % ( iid_rev_map.get(highest), highest, highestCos))\n",
    "  \n",
    "  \n",
    "mostsimilar(iid_map[\"m81834\"], emodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p0jIPMpWbkb5",
    "outputId": "a5d9ce67-9627-46c8-f026-dca969d99dd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targetMovieId = m69844 'Harry Potter and the Half-Blood Prince (2009)' (iid 917)\n"
     ]
    }
   ],
   "source": [
    "print(\"targetMovieId = %s '%s' (iid %d)\" % (iid_rev_map.get(917), getMovieTitle(917), 917))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UgUvFR0AK8XI",
    "outputId": "8d28b572-5324-46ab-bbaf-5276fe3cc97f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9724\n",
      "targetMovieId = m88125 'Harry Potter and the Deathly Hallows: Part 2 (2011)' (iid 1938)\n",
      "mostSimilar = m69844 (iid 917) with cosine of 0.765978 \n",
      "targetMovieId = m69844 'Harry Potter and the Half-Blood Prince (2009)' (iid 917)\n"
     ]
    }
   ],
   "source": [
    "mostsimilar(iid_map[\"m88125\"], emodel)\n",
    "print(\"targetMovieId = %s '%s' (iid %d)\" % (iid_rev_map.get(917), getMovieTitle(917), 917))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ENhT5FXX3qH9",
    "outputId": "d2249c06-9f69-46cc-8858-db78487d4618"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9724\n",
      "targetMovieId = m44 'Mortal Kombat (1995)' (iid 971)\n",
      "mostSimilar = m107338 (iid 2836) with cosine of 0.641704 \n",
      "targetMovieId = m107338 'Dampfnudelblues (2013)' (iid 2836)\n"
     ]
    }
   ],
   "source": [
    "mostsimilar(iid_map[\"m44\"], emodel)\n",
    "print(\"targetMovieId = %s '%s' (iid %d)\" % (iid_rev_map.get(2836), getMovieTitle(2836), 2836))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mxHfMZgbcdRu"
   },
   "source": [
    "## Evaluating performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OB8UJykycm3G",
    "outputId": "e5560671-96c0-4ad5-dafd-c7c4aedefe76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE 0.421, test RMSE 1.078\n"
     ]
    }
   ],
   "source": [
    "from spotlight.evaluation import rmse_score\n",
    "\n",
    "train_rmse = rmse_score(emodel, train)\n",
    "test_rmse = rmse_score(emodel, test)\n",
    "\n",
    "print('Train RMSE {:.3f}, test RMSE {:.3f}'.format(train_rmse, test_rmse))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WcRrTWx9lkoo"
   },
   "source": [
    "## 5. Tuning\n",
    "\n",
    "The task here is to train and evaluate new instances of ExplicitFactorizationModels using different numbers of latent factors, while leaving the other parameters unchanged (i.e. `n_iter=10, use_cuda=False, random_state=np.random.RandomState(SEED)`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "42zBfjCEL6pI",
    "outputId": "a82c9097-7556-4d35-f786-d8e79edc044f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss 5.744367660978172\n",
      "Epoch 1: loss 0.947946017112913\n",
      "Epoch 2: loss 0.6766490401535095\n",
      "Epoch 3: loss 0.5712967044379138\n",
      "Epoch 4: loss 0.5091710816833037\n",
      "Epoch 5: loss 0.4707542366430729\n",
      "Epoch 6: loss 0.4421984908890121\n",
      "Epoch 7: loss 0.4213783231717122\n",
      "Epoch 8: loss 0.4056830132686639\n",
      "Epoch 9: loss 0.3946505993416038\n",
      "Training of latent factors [8] took 11 seconds \n",
      "Latent factors[8] Train RMSE 0.577, test RMSE 1.011\n",
      "Epoch 0: loss 4.747190556948698\n",
      "Epoch 1: loss 0.8711058672847627\n",
      "Epoch 2: loss 0.6259694230518763\n",
      "Epoch 3: loss 0.49619132912234415\n",
      "Epoch 4: loss 0.4148417071828359\n",
      "Epoch 5: loss 0.3629063270231591\n",
      "Epoch 6: loss 0.3311092732356319\n",
      "Epoch 7: loss 0.3086943467017971\n",
      "Epoch 8: loss 0.29521983456385287\n",
      "Epoch 9: loss 0.283183237608475\n",
      "Training of latent factors [16] took 11 seconds \n",
      "Latent factors[16] Train RMSE 0.483, test RMSE 1.048\n",
      "Epoch 0: loss 4.308109072190296\n",
      "Epoch 1: loss 0.8099100989631459\n",
      "Epoch 2: loss 0.5096786611630947\n",
      "Epoch 3: loss 0.36366338669499265\n",
      "Epoch 4: loss 0.2919712712681746\n",
      "Epoch 5: loss 0.256977399221704\n",
      "Epoch 6: loss 0.2364347950567173\n",
      "Epoch 7: loss 0.22271785323944274\n",
      "Epoch 8: loss 0.21399798956287058\n",
      "Epoch 9: loss 0.20728879473820516\n",
      "Training of latent factors [32] took 17 seconds \n",
      "Latent factors[32] Train RMSE 0.421, test RMSE 1.078\n",
      "Epoch 0: loss 3.9413014178789116\n",
      "Epoch 1: loss 0.7578930313451381\n",
      "Epoch 2: loss 0.4151066137076933\n",
      "Epoch 3: loss 0.28894889538612545\n",
      "Epoch 4: loss 0.25092147908444645\n",
      "Epoch 5: loss 0.24193845967514604\n",
      "Epoch 6: loss 0.24069380331077153\n",
      "Epoch 7: loss 0.23878415716411192\n",
      "Epoch 8: loss 0.23337357312063628\n",
      "Epoch 9: loss 0.22632356983008264\n",
      "Training of latent factors [64] took 23 seconds \n",
      "Latent factors[64] Train RMSE 0.468, test RMSE 1.038\n"
     ]
    }
   ],
   "source": [
    "#solution here\n",
    "\n",
    "latent_factors = [8,16,32,64] # Set latent factors\n",
    "total_time,rmse_test_list,rmse_train_list = list(),list(),list()\n",
    "\n",
    "for lf in latent_factors:\n",
    "  tunning_model = ExplicitFactorizationModel(n_iter=10,\n",
    "                                      embedding_dim=lf, #this is Spotlight default\n",
    "                                      use_cuda=False,\n",
    "                                      random_state=np.random.RandomState(SEED) # ensure results are repeatable\n",
    "  )\n",
    "  current = time.time()\n",
    "\n",
    "  tunning_model.fit(train, verbose=True)\n",
    "\n",
    "  end = time.time()\n",
    "  diff = end - current\n",
    "  total_time.append(diff) # store total time\n",
    "  print('Training of latent factors [' + str(lf) + '] took %d seconds '% (diff))\n",
    "  \n",
    "  train_rmse = rmse_score(tunning_model, train)\n",
    "  rmse_train_list.append(train_rmse) # store train rmse\n",
    "\n",
    "  test_rmse = rmse_score(tunning_model, test)\n",
    "  rmse_test_list.append(test_rmse) # store test rmse\n",
    "  print('Latent factors[' + str(lf) + '] Train RMSE {:.3f}, test RMSE {:.3f}'.format(train_rmse, test_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 366
    },
    "id": "mZXufWpLq578",
    "outputId": "80fba7b6-dcf3-487c-cf65-dd13877a28c3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "\n",
    "plt.plot([str(lf) for lf in latent_factors],rmse_train_list, 'b', label='Train')\n",
    "plt.plot([str(lf) for lf in latent_factors],rmse_test_list, 'g', label='Test')\n",
    "plt.xlabel('Latent factor')\n",
    "plt.ylabel('RMSE value')\n",
    "plt.title('Train RMSE and Test RMSE for each latent factor')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig('Task5_Tuning.png') \n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RYTtH0_pl6sj"
   },
   "source": [
    "## Evaluating Other Models\n",
    "\n",
    "When evaluating models, it's important to compare to some reasonable baselines. \n",
    "\n",
    "Fortunately, Spotlight's `rmse_score()` method can be used to evaluate any Python object that adheres to the specification of the `predict()` function. For instance, we can make a baseline \"static\" scoring model, which returns the same scores for each user. This set of scores is passed as numpy array in the constructor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "D8Xd1X4TX2Tq"
   },
   "outputs": [],
   "source": [
    "class StaticModel:\n",
    "  \n",
    "  def __init__(self, staticscores):\n",
    "    self.numitems = len(staticscores)\n",
    "    self.staticscores = staticscores\n",
    "  \n",
    "  #uids are the user(s) we are requesting recommendations for;\n",
    "  #returns an array of scores, one for each item\n",
    "  #the array is duplicated for each user requested\n",
    "  def predict(self, uids, iids=None):\n",
    "    #this model returns all zeros, regardless of userid\n",
    "    \n",
    "    #we respond to one or more uids\n",
    "    uids = [uids] if isinstance(uids, int) else uids\n",
    "\n",
    "    #if iids is specificed, we filter predicts for those userids\n",
    "    iids = np.arange(self.numitems) if iids is None else iids\n",
    "    return [self.staticscores[iids] for u in uids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zhl_7mUxmdlv"
   },
   "source": [
    "For instance, we can make a static baseline that just returns 0 for every item, regardless of the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m3FVJWJzYhoC",
    "outputId": "17b86b0f-bf98-4be1-851f-eb64061727f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asking for 2 users, one item: [0.0, 0.0]\n",
      "Asking for one item: [0.0]\n",
      "Asking for two items: [array([0., 0.])]\n",
      "RMSE of our dummy model: 3.642758\n"
     ]
    }
   ],
   "source": [
    "mydummymodel = StaticModel(np.zeros(num_items))\n",
    "\n",
    "print(\"Asking for 2 users, one item: \" + str(mydummymodel.predict([0,1],0)))\n",
    "print(\"Asking for one item: \" + str(mydummymodel.predict(0,0)))\n",
    "print(\"Asking for two items: \" + str(mydummymodel.predict(0,[0,1])))\n",
    "print(\"RMSE of our dummy model: %f\" % rmse_score(mydummymodel, test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KSnTtOzAoA2l"
   },
   "source": [
    "## 6. Popularity-based Recommenders\n",
    "\n",
    "**Using ratings_df**, create three new instances of StaticModel as baselines:\n",
    "\n",
    "(a). the number of ratings for each item - you must linearly normalise this to be in the range 0-5.\n",
    "\n",
    "(b). the number of 5 scores received by an item - you must linearly normalise this to be in the range 0-5.\n",
    "\n",
    "(c). the average rating value for each item (no need to normalise - scores are already 0-5)\n",
    "\n",
    "Evaluate your baseline models in terms of RMSE, as well as providing their scores for particular iids, as requested in the quiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 555
    },
    "id": "i7ff_L2dMAGO",
    "outputId": "f6d12799-6bec-482f-fdbf-b7af993dd30e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of our dummy mode[l: 2.887788\n"
     ]
    }
   ],
   "source": [
    "## solution here\n",
    "\n",
    "# (a). the number of ratings for each item - linearly normalise this to be in the range 0-5.\n",
    "avg_no_rating = ratings_df.groupby(['movieId']).count() # count rating\n",
    "\n",
    "mid_array = ratings_df['movieId'].unique()\n",
    "no_rating_array = np.zeros_like(mid_array)\n",
    "\n",
    "for index,mid in enumerate(mid_array):  \n",
    "    no_rating_array[iid_map[mid]] = avg_no_rating.loc[mid]['userId']\n",
    "\n",
    "no_rating_array = ( no_rating_array  / no_rating_array.max() ) * 5 # normalize \n",
    "a_dummymodel = StaticModel(no_rating_array)\n",
    "print(\"RMSE of our dummy mode[l: %f\" % rmse_score(a_dummymodel, test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.2674772036474167]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_dummymodel.predict(0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of our dummy model: 3.308017\n"
     ]
    }
   ],
   "source": [
    "# (b). the number of 5 scores received by an item - you must linearly normalise this to be in the range 0-5.\n",
    "five_rating = ratings_df[ratings_df['rating'] == 5.0].groupby(['movieId']).count() # count 5 stars rating\n",
    "\n",
    "mid_array = ratings_df['movieId'].unique()\n",
    "no_five_array = np.zeros_like(mid_array)\n",
    "    \n",
    "for index,mid in enumerate(mid_array):\n",
    "    if mid in five_rating.index:\n",
    "        no_five_array[iid_map[mid]] = five_rating.loc[mid]['userId']\n",
    "\n",
    "no_five_array = ( no_five_array / no_five_array.max() ) * 5 # normalize \n",
    "b_dummymodel = StaticModel(no_five_array)\n",
    "print(\"RMSE of our dummy model: %f\" % rmse_score(b_dummymodel, test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.5359477124183007]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_dummymodel.predict(0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P8lVgdCQ19nl",
    "outputId": "9466a73d-ea1c-4207-f7b8-0d1a90667d4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of our dummy model: 0.881075\n"
     ]
    }
   ],
   "source": [
    "# (c). the average rating value for each item (no need to normalise - scores are already 0-5)\n",
    "item_avg_rating = ratings_df.groupby(['movieId']).mean()\n",
    "\n",
    "mid_array = ratings_df['movieId'].unique()\n",
    "avg_rating_array = np.zeros_like(mid_array)\n",
    "    \n",
    "for index,mid in enumerate(mid_array):\n",
    "    avg_rating_array[iid_map[mid]] = item_avg_rating.loc[mid]['rating']\n",
    "    \n",
    "c_dummymodel = StaticModel(avg_rating_array)    \n",
    "print(\"RMSE of our dummy model: %f\" % rmse_score(c_dummymodel, test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.9209302325581397]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_dummymodel.predict(0,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4aCiYTWaeobQ"
   },
   "source": [
    "# Implicit Recommendation\n",
    "\n",
    "This part uses a music dataset from [Last.fm](https://www.last.fm/) -- a Spotify-like music streaming service -- that was obtained by a researcher at Pompeu Fabra University (Barcelona, Spain). The relevant citation is:\n",
    "\n",
    "```\n",
    "  @book{Celma:Springer2010,\n",
    "      \tauthor = {Celma, O.},\n",
    "      \ttitle = {{Music Recommendation and Discovery in the Long Tail}},\n",
    "       \tpublisher = {Springer},\n",
    "       \tyear = {2010}\n",
    "      }\n",
    " ```\n",
    "\n",
    "You can have more information about the dataset at [this link](http://ocelma.net/MusicRecommendationDataset/lastfm-1K.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jsDavoa3qC64"
   },
   "source": [
    "## Dataset preparation\n",
    "\n",
    "This dataset is 600MB copmressed, and 2.4GB uncompressed. It takes 30 seconds to download on Colab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "M-drWmULel_p"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'rm' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0  641M    0  3849    0     0   9457      0 19:45:36 --:--:-- 19:45:36  9433\n",
      "  0  641M    0 1553k    0     0  1149k      0  0:09:31  0:00:01  0:09:30 1148k\n",
      "  0  641M    0 6477k    0     0  2753k      0  0:03:58  0:00:02  0:03:56 2751k\n",
      "  1  641M    1 10.2M    0     0  3114k      0  0:03:30  0:00:03  0:03:27 3113k\n",
      "  2  641M    2 13.4M    0     0  3150k      0  0:03:28  0:00:04  0:03:24 3149k\n",
      "  2  641M    2 17.4M    0     0  3335k      0  0:03:16  0:00:05  0:03:11 3609k\n",
      "  3  641M    3 21.0M    0     0  3399k      0  0:03:13  0:00:06  0:03:07 4008k\n",
      "  3  641M    3 24.6M    0     0  3425k      0  0:03:11  0:00:07  0:03:04 3743k\n",
      "  4  641M    4 27.7M    0     0  3404k      0  0:03:12  0:00:08  0:03:04 3598k\n",
      "  4  641M    4 29.8M    0     0  3270k      0  0:03:20  0:00:09  0:03:11 3375k\n",
      "  5  641M    5 34.1M    0     0  3381k      0  0:03:14  0:00:10  0:03:04 3429k\n",
      "  5  641M    5 38.4M    0     0  3466k      0  0:03:09  0:00:11  0:02:58 3551k\n",
      "  6  641M    6 41.1M    0     0  3372k      0  0:03:14  0:00:12  0:03:02 3295k\n",
      "  6  641M    6 44.3M    0     0  3403k      0  0:03:13  0:00:13  0:03:00 3402k\n",
      "  7  641M    7 47.5M    0     0  3390k      0  0:03:13  0:00:14  0:02:59 3614k\n",
      "  7  641M    7 51.1M    0     0  3412k      0  0:03:12  0:00:15  0:02:57 3478k\n",
      "  8  641M    8 54.9M    0     0  3443k      0  0:03:10  0:00:16  0:02:54 3391k\n",
      "  9  641M    9 58.5M    0     0  3457k      0  0:03:10  0:00:17  0:02:53 3676k\n",
      "  9  641M    9 62.2M    0     0  3474k      0  0:03:09  0:00:18  0:02:51 3666k\n",
      " 10  641M   10 65.8M    0     0  3486k      0  0:03:08  0:00:19  0:02:49 3762k\n",
      " 10  641M   10 69.7M    0     0  3508k      0  0:03:07  0:00:20  0:02:47 3801k\n",
      " 11  641M   11 74.1M    0     0  3555k      0  0:03:04  0:00:21  0:02:43 3924k\n",
      " 12  641M   12 78.2M    0     0  3583k      0  0:03:03  0:00:22  0:02:41 4021k\n",
      " 12  641M   12 82.2M    0     0  3606k      0  0:03:02  0:00:23  0:02:39 4091k\n",
      " 13  641M   13 85.7M    0     0  3603k      0  0:03:02  0:00:24  0:02:38 4058k\n",
      " 13  641M   13 88.2M    0     0  3564k      0  0:03:04  0:00:25  0:02:39 3796k\n",
      " 14  641M   14 92.0M    0     0  3576k      0  0:03:03  0:00:26  0:02:37 3662k\n",
      " 14  641M   14 95.6M    0     0  3570k      0  0:03:03  0:00:27  0:02:36 3513k\n",
      " 15  641M   15 97.4M    0     0  3514k      0  0:03:06  0:00:28  0:02:38 3085k\n",
      " 15  641M   15  100M    0     0  3514k      0  0:03:06  0:00:29  0:02:37 3081k\n",
      " 16  641M   16  104M    0     0  3537k      0  0:03:05  0:00:30  0:02:35 3396k\n",
      " 16  641M   16  108M    0     0  3540k      0  0:03:05  0:00:31  0:02:34 3356k\n",
      " 17  641M   17  111M    0     0  3516k      0  0:03:06  0:00:32  0:02:34 3217k\n",
      " 17  641M   17  114M    0     0  3526k      0  0:03:06  0:00:33  0:02:33 3594k\n",
      " 18  641M   18  117M    0     0  3495k      0  0:03:07  0:00:34  0:02:33 3383k\n",
      " 18  641M   18  121M    0     0  3504k      0  0:03:07  0:00:35  0:02:32 3304k\n",
      " 19  641M   19  124M    0     0  3504k      0  0:03:07  0:00:36  0:02:31 3278k\n",
      " 19  641M   19  128M    0     0  3515k      0  0:03:06  0:00:37  0:02:29 3508k\n",
      " 20  641M   20  132M    0     0  3540k      0  0:03:05  0:00:38  0:02:27 3635k\n",
      " 21  641M   21  136M    0     0  3547k      0  0:03:05  0:00:39  0:02:26 3901k\n",
      " 21  641M   21  140M    0     0  3564k      0  0:03:04  0:00:40  0:02:24 3983k\n",
      " 22  641M   22  144M    0     0  3568k      0  0:03:04  0:00:41  0:02:23 4032k\n",
      " 23  641M   23  147M    0     0  3572k      0  0:03:03  0:00:42  0:02:21 3999k\n",
      " 23  641M   23  152M    0     0  3597k      0  0:03:02  0:00:43  0:02:19 4034k\n",
      " 24  641M   24  154M    0     0  3565k      0  0:03:04  0:00:44  0:02:20 3707k\n",
      " 24  641M   24  157M    0     0  3554k      0  0:03:04  0:00:45  0:02:19 3478k\n",
      " 24  641M   24  160M    0     0  3535k      0  0:03:05  0:00:46  0:02:19 3259k\n",
      " 25  641M   25  162M    0     0  3519k      0  0:03:06  0:00:47  0:02:19 3073k\n",
      " 25  641M   25  166M    0     0  3524k      0  0:03:06  0:00:48  0:02:18 2890k\n",
      " 26  641M   26  170M    0     0  3530k      0  0:03:06  0:00:49  0:02:17 3224k\n",
      " 27  641M   27  174M    0     0  3555k      0  0:03:04  0:00:50  0:02:14 3564k\n",
      " 27  641M   27  179M    0     0  3578k      0  0:03:03  0:00:51  0:02:12 3976k\n",
      " 28  641M   28  182M    0     0  3563k      0  0:03:04  0:00:52  0:02:12 3978k\n",
      " 28  641M   28  186M    0     0  3570k      0  0:03:04  0:00:53  0:02:11 4010k\n",
      " 29  641M   29  189M    0     0  3569k      0  0:03:04  0:00:54  0:02:10 3948k\n",
      " 29  641M   29  191M    0     0  3550k      0  0:03:05  0:00:55  0:02:10 3500k\n",
      " 30  641M   30  195M    0     0  3545k      0  0:03:05  0:00:56  0:02:09 3215k\n",
      " 30  641M   30  198M    0     0  3539k      0  0:03:05  0:00:57  0:02:08 3290k\n",
      " 31  641M   31  201M    0     0  3534k      0  0:03:05  0:00:58  0:02:07 3159k\n",
      " 32  641M   32  205M    0     0  3546k      0  0:03:05  0:00:59  0:02:06 3296k\n",
      " 32  641M   32  208M    0     0  3544k      0  0:03:05  0:01:00  0:02:05 3478k\n",
      " 33  641M   33  212M    0     0  3544k      0  0:03:05  0:01:01  0:02:04 3531k\n",
      " 33  641M   33  216M    0     0  3555k      0  0:03:04  0:01:02  0:02:02 3739k\n",
      " 34  641M   34  220M    0     0  3561k      0  0:03:04  0:01:03  0:02:01 3880k\n",
      " 34  641M   34  223M    0     0  3558k      0  0:03:04  0:01:04  0:02:00 3705k\n",
      " 35  641M   35  227M    0     0  3568k      0  0:03:04  0:01:05  0:01:59 3856k\n",
      " 36  641M   36  231M    0     0  3566k      0  0:03:04  0:01:06  0:01:58 3829k\n",
      " 36  641M   36  234M    0     0  3549k      0  0:03:05  0:01:07  0:01:58 3475k\n",
      " 36  641M   36  236M    0     0  3546k      0  0:03:05  0:01:08  0:01:57 3343k\n",
      " 37  641M   37  240M    0     0  3543k      0  0:03:05  0:01:09  0:01:56 3343k\n",
      " 37  641M   37  243M    0     0  3543k      0  0:03:05  0:01:10  0:01:55 3222k\n",
      " 38  641M   38  246M    0     0  3537k      0  0:03:05  0:01:11  0:01:54 3150k\n",
      " 39  641M   39  251M    0     0  3552k      0  0:03:04  0:01:12  0:01:52 3590k\n",
      " 39  641M   39  255M    0     0  3561k      0  0:03:04  0:01:13  0:01:51 3776k\n",
      " 40  641M   40  258M    0     0  3563k      0  0:03:04  0:01:14  0:01:50 3849k\n",
      " 40  641M   40  261M    0     0  3556k      0  0:03:04  0:01:15  0:01:49 3726k\n",
      " 41  641M   41  265M    0     0  3563k      0  0:03:04  0:01:16  0:01:48 3944k\n",
      " 42  641M   42  269M    0     0  3572k      0  0:03:03  0:01:17  0:01:46 3867k\n",
      " 42  641M   42  273M    0     0  3580k      0  0:03:03  0:01:18  0:01:45 3854k\n",
      " 43  641M   43  278M    0     0  3589k      0  0:03:03  0:01:19  0:01:44 3968k\n",
      " 43  641M   43  281M    0     0  3589k      0  0:03:03  0:01:20  0:01:43 4094k\n",
      " 44  641M   44  285M    0     0  3588k      0  0:03:03  0:01:21  0:01:42 3957k\n",
      " 44  641M   44  287M    0     0  3578k      0  0:03:03  0:01:22  0:01:41 3665k\n",
      " 45  641M   45  290M    0     0  3569k      0  0:03:04  0:01:23  0:01:41 3406k\n",
      " 45  641M   45  293M    0     0  3559k      0  0:03:04  0:01:24  0:01:40 3092k\n",
      " 46  641M   46  296M    0     0  3561k      0  0:03:04  0:01:25  0:01:39 3095k\n",
      " 46  641M   46  300M    0     0  3567k      0  0:03:04  0:01:26  0:01:38 3227k\n",
      " 47  641M   47  304M    0     0  3566k      0  0:03:04  0:01:27  0:01:37 3364k\n",
      " 48  641M   48  308M    0     0  3576k      0  0:03:03  0:01:28  0:01:35 3677k\n",
      " 48  641M   48  312M    0     0  3582k      0  0:03:03  0:01:29  0:01:34 3959k\n",
      " 49  641M   49  316M    0     0  3589k      0  0:03:03  0:01:30  0:01:33 4070k\n",
      " 49  641M   49  319M    0     0  3582k      0  0:03:03  0:01:31  0:01:32 3847k\n",
      " 50  641M   50  323M    0     0  3587k      0  0:03:03  0:01:32  0:01:31 3962k\n",
      " 50  641M   50  326M    0     0  3586k      0  0:03:03  0:01:33  0:01:30 3763k\n",
      " 51  641M   51  330M    0     0  3584k      0  0:03:03  0:01:34  0:01:29 3627k\n",
      " 52  641M   52  334M    0     0  3587k      0  0:03:03  0:01:35  0:01:28 3550k\n",
      " 52  641M   52  337M    0     0  3587k      0  0:03:03  0:01:36  0:01:27 3684k\n",
      " 53  641M   53  342M    0     0  3603k      0  0:03:02  0:01:37  0:01:25 3901k\n",
      " 53  641M   53  346M    0     0  3605k      0  0:03:02  0:01:38  0:01:24 3966k\n",
      " 54  641M   54  350M    0     0  3608k      0  0:03:02  0:01:39  0:01:23 4066k\n",
      " 55  641M   55  353M    0     0  3611k      0  0:03:01  0:01:40  0:01:21 4067k\n",
      " 55  641M   55  355M    0     0  3595k      0  0:03:02  0:01:41  0:01:21 3746k\n",
      " 55  641M   55  358M    0     0  3581k      0  0:03:03  0:01:42  0:01:21 3158k\n",
      " 56  641M   56  360M    0     0  3572k      0  0:03:03  0:01:43  0:01:20 2918k\n",
      " 56  641M   56  361M    0     0  3551k      0  0:03:04  0:01:44  0:01:20 2413k\n",
      " 56  641M   56  363M    0     0  3536k      0  0:03:05  0:01:45  0:01:20 2026k\n",
      " 57  641M   57  366M    0     0  3524k      0  0:03:06  0:01:46  0:01:20 2071k\n",
      " 57  641M   57  367M    0     0  3507k      0  0:03:07  0:01:47  0:01:20 1980k\n",
      " 57  641M   57  369M    0     0  3489k      0  0:03:08  0:01:48  0:01:20 1774k\n",
      " 57  641M   57  371M    0     0  3477k      0  0:03:08  0:01:49  0:01:19 1942k\n",
      " 58  641M   58  373M    0     0  3463k      0  0:03:09  0:01:50  0:01:19 1938k\n",
      " 58  641M   58  374M    0     0  3445k      0  0:03:10  0:01:51  0:01:19 1785k\n",
      " 58  641M   58  376M    0     0  3431k      0  0:03:11  0:01:52  0:01:19 1799k\n",
      " 58  641M   58  378M    0     0  3416k      0  0:03:12  0:01:53  0:01:19 1846k\n",
      " 59  641M   59  381M    0     0  3414k      0  0:03:12  0:01:54  0:01:18 2030k\n",
      " 59  641M   59  383M    0     0  3402k      0  0:03:13  0:01:55  0:01:18 2045k\n",
      " 59  641M   59  384M    0     0  3385k      0  0:03:14  0:01:56  0:01:18 2035k\n",
      " 60  641M   60  386M    0     0  3376k      0  0:03:14  0:01:57  0:01:17 2132k\n",
      " 60  641M   60  389M    0     0  3369k      0  0:03:14  0:01:58  0:01:16 2299k\n",
      " 61  641M   61  393M    0     0  3375k      0  0:03:14  0:01:59  0:01:15 2489k\n",
      " 61  641M   61  396M    0     0  3374k      0  0:03:14  0:02:00  0:01:14 2731k\n",
      " 62  641M   62  400M    0     0  3378k      0  0:03:14  0:02:01  0:01:13 3230k\n",
      " 62  641M   62  402M    0     0  3371k      0  0:03:14  0:02:02  0:01:12 3256k\n",
      " 63  641M   63  405M    0     0  3364k      0  0:03:15  0:02:03  0:01:12 3253k\n",
      " 63  641M   63  407M    0     0  3355k      0  0:03:15  0:02:04  0:01:11 2869k\n",
      " 64  641M   64  410M    0     0  3356k      0  0:03:15  0:02:05  0:01:10 2935k\n",
      " 64  641M   64  413M    0     0  3349k      0  0:03:16  0:02:06  0:01:10 2654k\n",
      " 65  641M   65  417M    0     0  3357k      0  0:03:15  0:02:07  0:01:08 3028k\n",
      " 65  641M   65  420M    0     0  3352k      0  0:03:15  0:02:08  0:01:07 3045k\n",
      " 66  641M   66  423M    0     0  3356k      0  0:03:15  0:02:09  0:01:06 3375k\n",
      " 66  641M   66  428M    0     0  3363k      0  0:03:15  0:02:10  0:01:05 3521k\n",
      " 67  641M   67  431M    0     0  3361k      0  0:03:15  0:02:11  0:01:04 3688k\n",
      " 67  641M   67  434M    0     0  3362k      0  0:03:15  0:02:12  0:01:03 3483k\n",
      " 68  641M   68  436M    0     0  3350k      0  0:03:16  0:02:13  0:01:03 3313k\n",
      " 68  641M   68  440M    0     0  3354k      0  0:03:15  0:02:14  0:01:01 3299k\n",
      " 69  641M   69  444M    0     0  3361k      0  0:03:15  0:02:15  0:01:00 3317k\n",
      " 69  641M   69  448M    0     0  3366k      0  0:03:15  0:02:16  0:00:59 3483k\n",
      " 70  641M   70  451M    0     0  3367k      0  0:03:15  0:02:17  0:00:58 3504k\n",
      " 70  641M   70  454M    0     0  3363k      0  0:03:15  0:02:18  0:00:57 3707k\n",
      " 71  641M   71  458M    0     0  3366k      0  0:03:15  0:02:19  0:00:56 3708k\n",
      " 71  641M   71  461M    0     0  3366k      0  0:03:15  0:02:20  0:00:55 3514k\n",
      " 72  641M   72  465M    0     0  3368k      0  0:03:15  0:02:21  0:00:54 3443k\n",
      " 73  641M   73  468M    0     0  3369k      0  0:03:15  0:02:22  0:00:53 3407k\n",
      " 73  641M   73  470M    0     0  3362k      0  0:03:15  0:02:23  0:00:52 3332k\n",
      " 73  641M   73  473M    0     0  3362k      0  0:03:15  0:02:24  0:00:51 3232k\n",
      " 74  641M   74  477M    0     0  3365k      0  0:03:15  0:02:25  0:00:50 3320k\n",
      " 75  641M   75  481M    0     0  3371k      0  0:03:14  0:02:26  0:00:48 3444k\n",
      " 75  641M   75  485M    0     0  3374k      0  0:03:14  0:02:27  0:00:47 3530k\n",
      " 76  641M   76  488M    0     0  3371k      0  0:03:14  0:02:28  0:00:46 3640k\n",
      " 76  641M   76  490M    0     0  3355k      0  0:03:15  0:02:29  0:00:46 3163k\n",
      " 76  641M   76  492M    0     0  3351k      0  0:03:16  0:02:30  0:00:46 2962k\n",
      " 77  641M   77  495M    0     0  3348k      0  0:03:16  0:02:31  0:00:45 2687k\n",
      " 77  641M   77  498M    0     0  3349k      0  0:03:16  0:02:32  0:00:44 2601k\n",
      " 78  641M   78  501M    0     0  3347k      0  0:03:16  0:02:33  0:00:43 2637k\n",
      " 78  641M   78  504M    0     0  3348k      0  0:03:16  0:02:34  0:00:42 3128k\n",
      " 79  641M   79  508M    0     0  3348k      0  0:03:16  0:02:35  0:00:41 3235k\n",
      " 79  641M   79  510M    0     0  3346k      0  0:03:16  0:02:36  0:00:40 3292k\n",
      " 80  641M   80  515M    0     0  3351k      0  0:03:16  0:02:37  0:00:39 3427k\n",
      " 80  641M   80  518M    0     0  3353k      0  0:03:15  0:02:38  0:00:37 3508k\n",
      " 81  641M   81  522M    0     0  3357k      0  0:03:15  0:02:39  0:00:36 3637k\n",
      " 81  641M   81  524M    0     0  3349k      0  0:03:16  0:02:40  0:00:36 3377k\n",
      " 82  641M   82  526M    0     0  3342k      0  0:03:16  0:02:41  0:00:35 3210k\n",
      " 82  641M   82  528M    0     0  3331k      0  0:03:17  0:02:42  0:00:35 2700k\n",
      " 82  641M   82  530M    0     0  3327k      0  0:03:17  0:02:43  0:00:34 2512k\n",
      " 83  641M   83  533M    0     0  3321k      0  0:03:17  0:02:44  0:00:33 2166k\n",
      " 83  641M   83  536M    0     0  3322k      0  0:03:17  0:02:45  0:00:32 2437k\n",
      " 84  641M   84  540M    0     0  3324k      0  0:03:17  0:02:46  0:00:31 2738k\n",
      " 84  641M   84  542M    0     0  3322k      0  0:03:17  0:02:47  0:00:30 3034k\n",
      " 85  641M   85  546M    0     0  3321k      0  0:03:17  0:02:48  0:00:29 3117k\n",
      " 85  641M   85  549M    0     0  3321k      0  0:03:17  0:02:49  0:00:28 3344k\n",
      " 86  641M   86  553M    0     0  3324k      0  0:03:17  0:02:50  0:00:27 3415k\n",
      " 86  641M   86  556M    0     0  3324k      0  0:03:17  0:02:51  0:00:26 3324k\n",
      " 87  641M   87  559M    0     0  3322k      0  0:03:17  0:02:52  0:00:25 3320k\n",
      " 87  641M   87  561M    0     0  3316k      0  0:03:18  0:02:53  0:00:25 3161k\n",
      " 87  641M   87  562M    0     0  3300k      0  0:03:19  0:02:54  0:00:25 2601k\n",
      " 87  641M   87  564M    0     0  3293k      0  0:03:19  0:02:55  0:00:24 2241k\n",
      " 88  641M   88  565M    0     0  3282k      0  0:03:20  0:02:56  0:00:24 1874k\n",
      " 88  641M   88  567M    0     0  3274k      0  0:03:20  0:02:57  0:00:23 1604k\n",
      " 88  641M   88  568M    0     0  3264k      0  0:03:21  0:02:58  0:00:23 1449k\n",
      " 88  641M   88  570M    0     0  3258k      0  0:03:21  0:02:59  0:00:22 1734k\n",
      " 89  641M   89  574M    0     0  3260k      0  0:03:21  0:03:00  0:00:21 2109k\n",
      " 89  641M   89  576M    0     0  3256k      0  0:03:21  0:03:01  0:00:20 2335k\n",
      " 90  641M   90  580M    0     0  3256k      0  0:03:21  0:03:02  0:00:19 2620k\n",
      " 90  641M   90  581M    0     0  3249k      0  0:03:22  0:03:03  0:00:19 2728k\n",
      " 91  641M   91  583M    0     0  3243k      0  0:03:22  0:03:04  0:00:18 2707k\n",
      " 91  641M   91  586M    0     0  3238k      0  0:03:22  0:03:05  0:00:17 2415k\n",
      " 91  641M   91  589M    0     0  3241k      0  0:03:22  0:03:06  0:00:16 2688k\n",
      " 92  641M   92  593M    0     0  3244k      0  0:03:22  0:03:07  0:00:15 2787k\n",
      " 93  641M   93  597M    0     0  3248k      0  0:03:22  0:03:08  0:00:14 3194k\n",
      " 93  641M   93  601M    0     0  3253k      0  0:03:21  0:03:09  0:00:12 3629k\n",
      " 94  641M   94  605M    0     0  3256k      0  0:03:21  0:03:10  0:00:11 3931k\n",
      " 94  641M   94  609M    0     0  3260k      0  0:03:21  0:03:11  0:00:10 3944k\n",
      " 95  641M   95  613M    0     0  3263k      0  0:03:21  0:03:12  0:00:09 4001k\n",
      " 96  641M   96  617M    0     0  3271k      0  0:03:20  0:03:13  0:00:07 4145k\n",
      " 96  641M   96  619M    0     0  3265k      0  0:03:21  0:03:14  0:00:07 3725k\n",
      " 97  641M   97  623M    0     0  3266k      0  0:03:21  0:03:15  0:00:06 3651k\n",
      " 97  641M   97  626M    0     0  3269k      0  0:03:20  0:03:16  0:00:04 3617k\n",
      " 98  641M   98  630M    0     0  3270k      0  0:03:20  0:03:17  0:00:03 3526k\n",
      " 98  641M   98  632M    0     0  3265k      0  0:03:21  0:03:18  0:00:03 3035k\n",
      " 98  641M   98  634M    0     0  3260k      0  0:03:21  0:03:19  0:00:02 3071k\n",
      " 99  641M   99  639M    0     0  3266k      0  0:03:21  0:03:20  0:00:01 3269k\n",
      "100  641M  100  641M    0     0  3268k      0  0:03:20  0:03:20 --:--:-- 3253k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x lastfm-dataset-1K/\n",
      "x lastfm-dataset-1K/userid-profile.tsv\n",
      "x lastfm-dataset-1K/README.txt\n",
      "x lastfm-dataset-1K/userid-timestamp-artid-artname-traid-traname.tsv\n",
      "'ls' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!rm -rf lastfm-dataset-1K.tar.gz\n",
    "!curl -o \"lastfm-dataset-1K.tar.gz\" \"http://www.dcs.gla.ac.uk/~craigm/recsysH/lastfm-dataset-1K.tar.gz\"\n",
    "#backup location\n",
    "#!curl -o \"lastfm-dataset-1K.tar.gz\" http://macavaney.us/misc/lastfm-dataset-1K.tar.gz\n",
    "!tar -zxvf lastfm-dataset-1K.tar.gz\n",
    "!ls -lh lastfm-dataset-1K/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "kcxILh_-h773"
   },
   "outputs": [],
   "source": [
    "listens_df = pd.read_csv(\"lastfm-dataset-1K/userid-timestamp-artid-artname-traid-traname.tsv\",  names=['user', 'timestamp', 'artistid', 'artist', 'trackid', 'trackname'], header=None, sep='\\t')\n",
    "\n",
    "#Some tracks dont seem to have artists or track names, so lets drop them for simplicity.\n",
    "listens_df = listens_df[listens_df.artist.notnull()]\n",
    "listens_df = listens_df[listens_df.trackname.notnull()]\n",
    "\n",
    "#the dataframe is VERY big (19M interactions), so lets just work with a small sample of it (this will mean that effectiveness will be lower, but learning will be MUCH faster).\n",
    "listens_df = listens_df.sample(n=200000, random_state=np.random.RandomState(SEED))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GZSwFnZSgrNU"
   },
   "source": [
    "\n",
    "Let's look at the dataset. Note that the we don't have any explicit ratings by the users. We just know what they interacted with (and when). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "HAP3dPt-4KMi"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>artistid</th>\n",
       "      <th>artist</th>\n",
       "      <th>trackid</th>\n",
       "      <th>trackname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11087179</th>\n",
       "      <td>user_000593</td>\n",
       "      <td>2007-05-14T18:49:03Z</td>\n",
       "      <td>ad996aef-cc1c-42ac-af5c-619c370f4b8a</td>\n",
       "      <td>Emerson, Lake &amp; Palmer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Three Fates (Clotho/Lachesis/Atropos)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1911790</th>\n",
       "      <td>user_000093</td>\n",
       "      <td>2008-08-18T22:04:59Z</td>\n",
       "      <td>8c538f11-c141-4588-8ecb-931083524186</td>\n",
       "      <td>Bloc Party</td>\n",
       "      <td>315a301e-e764-4adf-91c6-e90a22320106</td>\n",
       "      <td>Positive Tension</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11099786</th>\n",
       "      <td>user_000594</td>\n",
       "      <td>2008-04-06T10:57:45Z</td>\n",
       "      <td>65f4f0c5-ef9e-490c-aee3-909e7ae6b2ab</td>\n",
       "      <td>Metallica</td>\n",
       "      <td>683c89fe-2be8-4ed2-8e58-68b2343cb8d5</td>\n",
       "      <td>Through The Never</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12076983</th>\n",
       "      <td>user_000651</td>\n",
       "      <td>2008-05-10T07:14:45Z</td>\n",
       "      <td>3ca09fae-fdee-4771-bab9-244708515a98</td>\n",
       "      <td>Omarion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ice Box [Orangefuzzz Weather Advisory Radio Mix]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2680461</th>\n",
       "      <td>user_000137</td>\n",
       "      <td>2009-03-11T23:17:22Z</td>\n",
       "      <td>af84ee9f-534a-4f7f-844b-188ba1c47e87</td>\n",
       "      <td>Los RodrÃ­guez</td>\n",
       "      <td>76b83f07-3763-4c17-8d24-28040d85354a</td>\n",
       "      <td>Dulce Condena</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 user             timestamp  \\\n",
       "11087179  user_000593  2007-05-14T18:49:03Z   \n",
       "1911790   user_000093  2008-08-18T22:04:59Z   \n",
       "11099786  user_000594  2008-04-06T10:57:45Z   \n",
       "12076983  user_000651  2008-05-10T07:14:45Z   \n",
       "2680461   user_000137  2009-03-11T23:17:22Z   \n",
       "\n",
       "                                      artistid                  artist  \\\n",
       "11087179  ad996aef-cc1c-42ac-af5c-619c370f4b8a  Emerson, Lake & Palmer   \n",
       "1911790   8c538f11-c141-4588-8ecb-931083524186              Bloc Party   \n",
       "11099786  65f4f0c5-ef9e-490c-aee3-909e7ae6b2ab               Metallica   \n",
       "12076983  3ca09fae-fdee-4771-bab9-244708515a98                 Omarion   \n",
       "2680461   af84ee9f-534a-4f7f-844b-188ba1c47e87           Los RodrÃ­guez   \n",
       "\n",
       "                                       trackid  \\\n",
       "11087179                                   NaN   \n",
       "1911790   315a301e-e764-4adf-91c6-e90a22320106   \n",
       "11099786  683c89fe-2be8-4ed2-8e58-68b2343cb8d5   \n",
       "12076983                                   NaN   \n",
       "2680461   76b83f07-3763-4c17-8d24-28040d85354a   \n",
       "\n",
       "                                                 trackname  \n",
       "11087179             Three Fates (Clotho/Lachesis/Atropos)  \n",
       "1911790                                   Positive Tension  \n",
       "11099786                                 Through The Never  \n",
       "12076983  Ice Box [Orangefuzzz Weather Advisory Radio Mix]  \n",
       "2680461                                      Dulce Condena  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listens_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MLGzG9Rig3E6"
   },
   "source": [
    "## An implicit recommendation approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U03zZ6CH---1"
   },
   "source": [
    "We can construct [Interaction](https://maciejkula.github.io/spotlight/interactions.html) objects for Spotlight in the same way as before. The only difference is that this time we do not record the user's ratings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "jcRhNWXzg7LT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Interactions dataset (973 users x 125076 items x 200000 interactions)>\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from itertools import count\n",
    "\n",
    "#we cant trust the musicbrainz ids to exist, so lets build items ids based on artist & trackname attributes\n",
    "LFMiid_map = defaultdict(count().__next__)\n",
    "LFMiids = np.array([LFMiid_map[artist+\"/\"+trackname] for artist,trackname in listens_df[[\"artist\",\"trackname\"]].values ], dtype=np.int32)\n",
    "\n",
    "LFMuid_map = defaultdict(count().__next__)\n",
    "LFMuids = np.array([LFMuid_map[uid] for uid in listens_df[\"user\"].values ], dtype=np.int32)\n",
    "#freeze uid_map and iid_map so no more mapping are created\n",
    "LFMuid_map.default_factory = None\n",
    "LFMiid_map.default_factory = None\n",
    "\n",
    "LFMuid_rev_map = {v: k for k, v in LFMuid_map.items()}\n",
    "LFMiid_rev_map = {v: k for k, v in LFMiid_map.items()}\n",
    "\n",
    "from spotlight.interactions import Interactions\n",
    "from spotlight.cross_validation import random_train_test_split\n",
    "\n",
    "#NB: we will set num_users and num_items here\n",
    "imp_dataset = Interactions(user_ids=LFMuids, item_ids=LFMiids, num_users=len(LFMuid_map), num_items=len(LFMiid_map))\n",
    "#we could add the timestamps here if we were doing sequence recommendation\n",
    "\n",
    "print(imp_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "22dmr7JKqUnz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Interactions dataset (973 users x 125076 items x 160000 interactions)>\n",
      "<Interactions dataset (973 users x 125076 items x 40000 interactions)>\n"
     ]
    }
   ],
   "source": [
    "from spotlight.cross_validation import random_train_test_split\n",
    "\n",
    "itrain, itest = random_train_test_split(imp_dataset, random_state=np.random.RandomState(SEED))\n",
    "print(itrain)\n",
    "print(itest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "co3ZwYgkhKvq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss 0.9663112545967102\n",
      "Epoch 1: loss 0.49532520871162417\n",
      "Epoch 2: loss 0.19036926214694977\n",
      "Epoch 3: loss 0.11518941595554352\n",
      "Epoch 4: loss 0.08347183648347854\n",
      "Training took 122 seconds\n"
     ]
    }
   ],
   "source": [
    "from spotlight.factorization.implicit import ImplicitFactorizationModel\n",
    "import time  \n",
    "\n",
    "imodel = ImplicitFactorizationModel(n_iter=5, \n",
    "                                    embedding_dim=32, #this is Spotlight default\n",
    "                                    use_cuda=False,\n",
    "                                    random_state=np.random.RandomState(SEED) # ensure results are repeatable\n",
    ")\n",
    "current = time.time()\n",
    "\n",
    "imodel.fit(itrain, verbose=True)\n",
    "end = time.time()\n",
    "diff = end - current\n",
    "print(\"Training took %d seconds\" % (diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zso4C5wehLog"
   },
   "source": [
    "Note that the scores vary in magnitude - we're not predicting a rating, we just need to have scores in order to rank the items in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "AR_qbWXEhUDB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -4.7575655   5.2617598  -9.297517  ...  -9.027842  -11.65852\n",
      " -13.5019245]\n",
      "125076\n"
     ]
    }
   ],
   "source": [
    "print(imodel.predict(0))\n",
    "print(len(imodel.predict(0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iyZ3PyAxhdDF"
   },
   "source": [
    "Now that we have the scores of all items for a given user, we need to identify the top-scored ones, i.e. those that we would present to the user. \n",
    "\n",
    "## 7. Track Analysis\n",
    "\n",
    "What are the top scored 10 tracks recommended for user uid 4?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "V93_Bxw3MG1F"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 tracks recommend for user uid4 (user_000137)\n",
      "1.['Evanescence/Sweet Sacrifice'] score[13.124208]\n",
      "2.['Mgmt/Kids'] score[12.6752615]\n",
      "3.['The Killers/Bones'] score[12.663373]\n",
      "4.['Nelly Furtado/Say It Right'] score[12.464312]\n",
      "5.['Kings Of Leon/Use Somebody'] score[12.43695]\n",
      "6.['Amy Winehouse/Back To Black'] score[12.17378]\n",
      "7.['Red Hot Chili Peppers/The Zephyr Song'] score[11.530693]\n",
      "8.['Radiohead/Fake Plastic Trees'] score[10.85973]\n",
      "9.['Incubus/Drive'] score[10.710889]\n",
      "10.['Him/The Funeral Of Hearts'] score[10.703493]\n"
     ]
    }
   ],
   "source": [
    "def tracksForUser(uid : str, k : int = 4):\n",
    "\n",
    "    all_item_score = imodel.predict(uid) # Get items score for input user\n",
    "    sort_score = np.sort(all_item_score)[::-1] # Sort score highest to low\n",
    "    top_score = list()\n",
    "    position_score = list()    \n",
    "    \n",
    "    for i in range(k):\n",
    "        position_score.append(np.argwhere(all_item_score==sort_score[i])) # Get position of item for each top k score \n",
    "        top_score.append(all_item_score[np.argwhere(all_item_score==sort_score[i])]) # Get top k score from position\n",
    "\n",
    "    position_score_array = np.asarray(position_score).reshape(-1,1)\n",
    "\n",
    "    recommend_list = list()\n",
    "    \n",
    "    for pos in position_score_array:\n",
    "        recommend_list.append(LFMiid_rev_map.get(pos[0])) # Find artist and track from top k score\n",
    "\n",
    "    top_score_array = np.asarray(top_score).reshape(-1,1)\n",
    "    recommend_array = np.asarray(recommend_list).reshape(-1,1)\n",
    "    \n",
    "    return [top_score_array, recommend_array]\n",
    "\n",
    "uid = 4\n",
    "k = 10\n",
    "top_score, top_rec = tracksForUser(uid=uid, k=k)\n",
    "\n",
    "print(\"Top \" +  str(k) + \" tracks recommend for user uid\" + str(uid) + \" (\" + LFMuid_rev_map.get(uid) +\")\")\n",
    "\n",
    "for i in range(len(top_score)):\n",
    "    print(str(i+1) + \".\" + str(top_rec[i]) + \" score\" + str(top_score[i]) + \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jWFSAuQ40p2Y"
   },
   "source": [
    "## 8. Artist Analysis\n",
    "\n",
    "Look at the artists actually listened to by uid 4, and compare/contrast with the predictions of the recommender. It's useful to examine how many times each artist was listened to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "T2wFfGfcMJcc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>artist</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Soda Stereo</th>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gustavo Cerati</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Radiohead</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lucybell</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Silvio RodrÃ­guez</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Inti Illimani\\Inti+Quila</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Interpol</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Incubus</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fito PÃ¡ez, Gustavo Cerati Y Charly GarcÃ­a</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Leverage</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>146 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           count\n",
       "artist                                          \n",
       "Soda Stereo                                   39\n",
       "Gustavo Cerati                                36\n",
       "Radiohead                                     31\n",
       "Lucybell                                      27\n",
       "Silvio RodrÃ­guez                              16\n",
       "...                                          ...\n",
       "Inti Illimani\\Inti+Quila                       1\n",
       "Interpol                                       1\n",
       "Incubus                                        1\n",
       "Fito PÃ¡ez, Gustavo Cerati Y Charly GarcÃ­a      1\n",
       "Leverage                                       1\n",
       "\n",
       "[146 rows x 1 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uid = 4\n",
    "user = LFMuid_rev_map.get(uid)\n",
    "\n",
    "listen_artist = listens_df[listens_df[\"user\"] == user][['artist','trackname']].groupby('artist').count()\n",
    "listen_artist.rename(columns = ({'trackname' : 'count'}),inplace=True)\n",
    "sort_listen_artist = listen_artist[listen_artist['count'] >= 1].sort_values(by=['count'], ascending=False)\n",
    "sort_listen_artist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t2FWymqQRxKj"
   },
   "source": [
    "I observed that uid 4 listened frequently to \"Radiohead\" (rank 3), while a Radiohead song was among the top 10 ranked songs in our predicted model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XmTNae6Romuk"
   },
   "source": [
    "## Evaluating an implicit recommender\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "14Q2TTpZuHON"
   },
   "source": [
    "We can examine the MRR of the implicit model we have learned. We pass it the test set (which contains knowledge of what the user *actually* clicked), as our ground truth. \n",
    "\n",
    "In the second variant, we also pass the training data. Give a look at the  implementation of [mrr_score()](https://github.com/cmacdonald/spotlight/blob/master/spotlight/evaluation.py#L8) to understand what it is doing, and why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "oLV71LSjt-k2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03720125940064275\n",
      "0.008104536778740273\n"
     ]
    }
   ],
   "source": [
    "from spotlight.evaluation import mrr_score\n",
    "\n",
    "#evaluate on this dataset takes approx 1 minute\n",
    "#!date\n",
    "print(mrr_score(imodel, itest).mean())\n",
    "#!date\n",
    "print(mrr_score(imodel, itest,  train=itrain).mean())\n",
    "#!date\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LjM_kZNtAE2k"
   },
   "source": [
    "How to interpret an MRR score - we know it has a range [0,1] with 1 being best. 1 means, on average across all users, we make a relevant prediction at rank 1; 0.5 means, on average, at rank 2. This is a very rough rule-of-thumb - MRR isn't a linear measure, so  a few poor predictions affect the average more than a few good ones.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hL2jRiGF2uLb"
   },
   "source": [
    "## Task 9. Listens and Recommendations\n",
    "\n",
    "*   Pick the user with the lowest uid that has RR=1 (you should not specify `train=` when making this choice). How many listens (ie. how many times they have listened to any song) did they have in the training dataset?\n",
    "*   Similarly, pick the user with the lowest uid that had the lowest RR. How many listens did they have in the training dataset?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_score = mrr_score(imodel, itest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "B6H0l1S6nNcd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total times user uid31 (user_000833) (RR=1.0) listen to a song: 950 times\n",
      "Total times user uid1 (user_000093) (RR=0.0) listen to a song: 442 times\n"
     ]
    }
   ],
   "source": [
    "user_rr_pos = np.argwhere(m_score==1) # Find position of uid with RR=1\n",
    "user_rr_pos = user_rr_pos.reshape(1,-1)[0]\n",
    "\n",
    "high_rr_uid = LFMuid_rev_map.get(user_rr_pos[0]) # Select lowest uid\n",
    "\n",
    "high_current_listen = listens_df[listens_df[\"user\"] == high_rr_uid]['trackname'].count()\n",
    "print(\"Total times user uid\" + str(user_rr_pos[0]) + \" (\" + high_rr_uid +\") (RR=\" + str(m_score[user_rr_pos[0]]) + \") listen to a song: \" + str(high_current_listen) + \" times\")\n",
    "\n",
    "user_low_rr = np.argwhere(m_score==0)\n",
    "user_low_rr = user_low_rr.reshape(1,-1)[0]\n",
    "\n",
    "low_rr_uid = LFMuid_rev_map.get(user_low_rr[0]) # Select lowest uid\n",
    "\n",
    "low_current_listen = listens_df[listens_df[\"user\"] == low_rr_uid]['trackname'].count()\n",
    "print(\"Total times user uid\" + str(user_low_rr[0]) + \" (\" + low_rr_uid +\") (RR=\" + str(m_score[user_low_rr[0]]) + \") listen to a song: \" + str(low_current_listen) + \" times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "zCI34-U48HHI"
   },
   "outputs": [],
   "source": [
    "uid_no_listen = np.zeros_like(m_score)\n",
    "for usrid in range(len(np.unique(LFMuids))):\n",
    "    uid_no_listen[usrid] = listens_df[listens_df[\"user\"] == LFMuid_rev_map.get(usrid)]['trackname'].count()\n",
    "    uid_no_listen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "bin = plt.hist(uid_no_listen, bins=10, log=True)\n",
    "\n",
    "#plt.ylim(0,10**3)\n",
    "plt.xlabel('Number of listening time')\n",
    "plt.ylabel('Total users')\n",
    "\n",
    "\n",
    "plt.savefig('Number_of_listen_uid.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([613., 192.,  95.,  31.,  19.,  10.,   6.,   3.,   2.,   2.]),\n",
       " array([1.0000e+00, 1.8570e+02, 3.7040e+02, 5.5510e+02, 7.3980e+02,\n",
       "        9.2450e+02, 1.1092e+03, 1.2939e+03, 1.4786e+03, 1.6633e+03,\n",
       "        1.8480e+03]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5kjpISm3nwAy"
   },
   "source": [
    "Many users have very few listens. Lets set 20 listens as a threshold.\n",
    "\n",
    "Lets define users with < 20 listens as cold-start users.\n",
    "How many cold-start users are there?\n",
    "What is the MRR for ONLY these users, versus \"normal\" with 20 or more listens.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many cold-start users?: 137\n",
      "0.002867570385818561\n"
     ]
    }
   ],
   "source": [
    "listen20 = list()\n",
    "\n",
    "for i in range(len(LFMuid_rev_map)):\n",
    "    listen_co = listens_df[listens_df[\"user\"] == LFMuid_rev_map.get(i)]['trackname'].count()\n",
    "    if (listen_co < 20):\n",
    "        listen20.append(i)\n",
    "        \n",
    "listen20_array = np.asarray(listen20)\n",
    "print('How many cold-start users?:', len(listen20))\n",
    "print(m_score[listen20_array].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many user listen 20 or more?: 836\n",
      "0.04282771322245006\n"
     ]
    }
   ],
   "source": [
    "listen = list()\n",
    "\n",
    "for i in range(len(LFMuid_rev_map)):\n",
    "    listen_co = listens_df[listens_df[\"user\"] == LFMuid_rev_map.get(i)]['trackname'].count()\n",
    "    if (listen_co >= 20):\n",
    "        listen.append(i)\n",
    "print('How many user listen 20 or more?:', len(listen))\n",
    "print(m_score[listen].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MR_l43rFc7eo"
   },
   "source": [
    "## 10 - BPR\n",
    "\n",
    "Finally, let's compare the *pointwise* implicit factorisation model with *BPR*. BPR is a very key recommendation model in the literature, which is widely used today as a baseline in many research papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "4oiCB4PuMQ_f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss 0.4740972496986389\n",
      "Epoch 1: loss 0.1468369757294655\n",
      "Epoch 2: loss 0.024808171512186526\n",
      "Epoch 3: loss 0.014375458194687963\n",
      "Epoch 4: loss 0.011113861539959908\n",
      "Training took 122 seconds\n",
      "MRR Score of model with BPR: 0.05814735966328977\n"
     ]
    }
   ],
   "source": [
    "from spotlight.factorization.implicit import ImplicitFactorizationModel\n",
    "import time  \n",
    "\n",
    "imodel_BPR = ImplicitFactorizationModel(n_iter=5, \n",
    "                                    embedding_dim=32, #this is Spotlight default\n",
    "                                    loss='bpr',\n",
    "                                    use_cuda=False,\n",
    "                                    random_state=np.random.RandomState(SEED) # ensure results are repeatable\n",
    ")\n",
    "current = time.time()\n",
    "\n",
    "imodel_BPR.fit(itrain, verbose=True)\n",
    "end = time.time()\n",
    "diff = end - current\n",
    "print(\"Training took %d seconds\" % (diff))\n",
    "\n",
    "print(\"MRR Score of model with BPR:\", mrr_score(imodel_BPR, itest).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR Score of normal model: 0.03720125940064275\n"
     ]
    }
   ],
   "source": [
    "print(\"MRR Score of normal model:\", mrr_score(imodel, itest).mean())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of RecSys 2021M - Ex2 TEMPLATE.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
